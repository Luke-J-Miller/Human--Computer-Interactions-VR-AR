# Interactive Learning with AR
## Weekend 1: Foundations of Unity and ML Integration
[Lesson Slides](https://docs.google.com/presentation/d/1utVYhSMCL8EviY2QNkuyc3JoUDwlz9j4vyebENd_kko/edit?usp=sharing)
### Session 1: Setting Up and Unity Basics
- Objective: Introduce Unity and build a basic interactive scene.

#### Getting Started with Unity
- Download, install, and configure Unity.
- Overview of the Unity interface: Hierarchy, Scene, Game, Inspector, and Project tabs.
#### Building the First Scene 
- Adding objects (3D models, UI elements) and adjusting transforms.
- - Adding physics components: Rigidbodies and colliders.
#### Basic Interactions with Unity
- Adding scripts (in C#) to objects for interactivity.
- Example: Making an object move or react to user input.
#### Hands-On:
- Create a virtual room with basic interactive objects (e.g., a button that triggers an animation).

### Day 2: ML Basics and Unity Integration
- Objective: Introduce ML concepts and incorporate them into Unity.

#### Introduction to ML for Non-Programmers
- Key concepts: What is ML, and how does it apply to AR/VR?
- Pre-trained models and their utility for non-experts.
#### Object Recognition Using ML
Overview of pre-trained object recognition models (e.g., MobileNet).
How ML models process images and make predictions.
#### Integrating ML into Unity 
- Tools: Unity Barracuda or TensorFlow for Unity.
- Example: Setting up a real-time object detection pipeline in Unity.
#### Hands-On:
- Create a Unity scene with a live camera feed and an object detection model that highlights detected objects in AR.

## Weekend 2: Building the Final AR Project
### Day 3: AR Development with Meta Oculuses
- Objective: Set up the Meta Oculus for AR and begin adding AR functionality.

#### Introduction to AR with Unity
- Overview of AR in Unity and how it differs from VR.
- Setting up Unity for AR development (using the Meta Oculus SDK).
#### Augmented Interactions 
- Anchoring virtual objects in real-world spaces.
- Adding basic AR interactions (e.g., grabbing and moving objects).
#### Enhancing AR Scenes 
- Adding animations and sounds to make the experience more engaging.
#### Hands-On:
- Build a scene where virtual objects are anchored to real-world positions and interact with the userâ€™s input.

### Day 4: Finalizing and Presenting the AR Project
- Objective: Combine the elements developed in previous sessions to create a functional AR project.

#### Polishing the Experience 
- Adding UI overlays (e.g., instructions or notifications).
- Debugging and improving interactions for a seamless user experience.
#### Showcase Preparation 
- Participants finalize their projects and test them with peers.
#### Showcase and Feedback 
- Participants present their AR applications to the group.
- Discuss challenges, solutions, and next steps.
#### Hands-On:
- Complete and present the final AR project, incorporating object detection, interactions, and animations.
