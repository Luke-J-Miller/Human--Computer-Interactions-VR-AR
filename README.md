# Human--Computer-Interactions-VR-AR

 ## [Week 1: Lesson 1]{https://github.com/Luke-J-Miller/Human--Computer-Interactions-VR-AR/tree/main/Week%201%3A%20Lesson%201, }
 ### Lecture 1:
 - Learn spatial computing and AI basics.
 - Conceptualize an AI-driven spatial computing application.
 ### Tutorial 1:
 - Basics of Machine Learning (ML) and Deep Learning
 - Relationship between Machine Learning and Deep Learning, with 
emphasis on Convolutional Neural Networks (CNNs)
 - Introduction to YOLO (You Only Look Once)
- Training a custom YOLO object detection model from scratch using 
Darknet
 ### Assignment 1:
 - Practical exercises to enhance Machine Learning and Deep Learning skills
 - Utilization of popular Python libraries such as Scikit-learn, NumPy, and 
Pandas
 - Training a custom YOLO model
 - Selection of a dataset for training the model
 - Application of custom data augmentations to prepare for model training
 - Hands-on experience in building and refining a deep learning model for 
object detection
 #### Learning Outcome: 
 Understand spatial computing's role across industries and the 
foundational principles of AI and deep learning.
 ## Week 1: Lesson 2
 ### Lecture:
 - Explore Advanced deep learning integration.
 - Enhance the initial concept with AR/VR features.
 ### Tutorial:
 - Exploring object detection in virtual reality (VR) using Oculus Quest 2
 - Focusing on detecting various fruits using a YOLO object detection model
 - Utilizing Unity for VR development
 - Implementing object detection with YOLO (You Only Look Once)
 - Incorporating Flask as the Python web framework
 - Coding with PyCharm for Flask development and Visual Studio Code for 
C# programming in Unity
### Assignment: Custom Object Detection in Unity
 - Training a YOLO model with a custom dataset for object detection in 
Unity
 - Incorporating custom objects or environments from the internet
 - Optionally recording personal environments or objects using 3D scanning 
apps, subject to device compatibility
 #### Learning Outcomes: 
 Gain hands-on experience with spatial data analysis and learn to 
enhance AR/VR applications using AI and Unity.
 ## Week 2: Lesson 3
 ### Lecture:
 - Advance in spatial data analysis using SLAM (Simultaneous Localization 
And Mapping).
 - Explainability using LLMs for Spatial Computing
 - Further develop the AR/VR application with AI interactivity.
### Tutorial:
 - Introduction to advanced integration of Unity, YOLO, Flask, Large 
Language Models (LLM), and SLAM (Simultaneous Localization And 
Mapping) scanning
 - Creating an interactive spatial environment for robust object detection
 - Utilizing SLAM for a deeper understanding of surroundings and spatial 
context
 - Integration of LLMs to process and interpret detected objects within their 
spatial environment
 ### Assignment: SLAM-Enabled Object Detection with LLM Insights
 - Enhancing YOLO model training with a custom dataset for object 
detection within a SLAM-enabled environment
 - Integrating SLAM technology to understand the spatial context of 
detection
 - Utilizing LLM prompts to extract deeper insights and explanations from 
object detection results
 - Enriching the interactive experience with spatial awareness and 
interpretative depth
 #### Learning Outcome: Develop skills in SLAM and LLMs and deep learning model 
integration for AR/VR.
##  Week 2: Session 4: Project Review/Presentation
 - Finalize AR/VR metaverse application with advanced AI and LLM features.
 - Prepare and deliver final presentations.
#### Learning Outcome: Achieve proficiency in advanced AR/VR application development.
and integration of deep learning and LLMs for spatial computing applications.
